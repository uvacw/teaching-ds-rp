{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieving and cleaning data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook can be used to get the data from your experiment saved as a CSV\n",
    "file. You need to put the SQL file you receive in the phpmyadmin tool (see\n",
    "Canvas on instructions how to do this) and then run this code. Watch out!\n",
    "Sometimes you need to make small adaptations (indicated in the notebook)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sqlalchemy in /Users/dzhang/anaconda3/lib/python3.10/site-packages (2.0.31)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in /Users/dzhang/anaconda3/lib/python3.10/site-packages (from sqlalchemy) (4.11.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, inspect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code connects to the SQL database from phpmyadmin and gets the\n",
    "names of all the tables that are present. For each group there should be several\n",
    "tables such as \"calibration\", \"userconsent\" or \"propositions\" -- but there might\n",
    "be some columns only present for some of the groups.\n",
    "\n",
    "**!! IMPORTANT !! You need to change the first command to reflect the name that\n",
    "you have given the database. In this example the database was called \"group25\",\n",
    "replace this with the name the database has in your phpmyadmin**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "group21_calibration\n",
      "group21_pre_propositions\n",
      "group21_propositions\n",
      "group21_propositions1\n",
      "group21_propositions2\n",
      "group21_propositions3\n",
      "group21_propositions4\n",
      "group21_recommendation\n",
      "group21_userallergies\n",
      "group21_userconsent\n",
      "group21_userdemograph\n",
      "group21_usermancheck\n",
      "group21_userpresatisfaction\n",
      "group21_users\n",
      "group21_usersatisfaction\n",
      "group21_usersatisfaction1\n",
      "group21_usersatisfaction2\n",
      "group21_usersatisfaction3\n",
      "group21_usersatisfaction4\n",
      "group21_userselection\n"
     ]
    }
   ],
   "source": [
    "# Create a connection to the MySQL database using SQLAlchemy\n",
    "engine = create_engine('mysql+pymysql://root:@localhost/group21_final') # !!! Change database name here !!!\n",
    "\n",
    "# Use the inspect module to get table names\n",
    "inspector = inspect(engine)\n",
    "tables = inspector.get_table_names()\n",
    "\n",
    "# Print the list of all tables\n",
    "for table in tables:\n",
    "    print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we also want to know to which statements the different likert scale items\n",
    "correspond (important for later analysis), we can retrieve a kind of \"codebook\"\n",
    "for this from the database. The information about the likert scale items can be\n",
    "stored in a few different tables: pre_propositions (asked before the\n",
    "calibration/recommendation), propositions (asked after the recommendation), and\n",
    "sometimes propositions1 if there were more questions than fit on the pages. Your\n",
    "group might have one, two, or all of these tables. Running the code below\n",
    "outputs the saved (pre-)propositions with their id, question wording, and scale\n",
    "(usually 5 or 7 point). You can use the id to look up the matching column in the\n",
    "csv dataframe later.\n",
    "\n",
    "With the code below we are retrieving the tables, loading them into pandas\n",
    "dataframes and adding a prefix to the item names (pre* or post*) as often the\n",
    "IDs are the same for prepropositions and propositions, so we want to be able to\n",
    "keep them apart later.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>scale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pre_2</td>\n",
       "      <td>Overall, I am satisfied with how easy it is to...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pre_3</td>\n",
       "      <td>It is simple to use this system.</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pre_4</td>\n",
       "      <td>I feel comfortable using this system.</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pre_5</td>\n",
       "      <td>The information (such as online help, on-scree...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pre_6</td>\n",
       "      <td>It is easy to find the infromation I need</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pre_7</td>\n",
       "      <td>The information provded with the system is eas...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>post_8</td>\n",
       "      <td>Provide useful suggestions</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>post_9</td>\n",
       "      <td>Make decisions easier</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>post_10</td>\n",
       "      <td>Are a good way to learn about different produc...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>post_11</td>\n",
       "      <td>Offer suggestions that I might not have though...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>post_12</td>\n",
       "      <td>Have access to and can process more informatio...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>post_13</td>\n",
       "      <td>Are reliable</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>post_14</td>\n",
       "      <td>Are dependable</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>post_15</td>\n",
       "      <td>Are designed with the best intentions in mind</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>post_16</td>\n",
       "      <td>Can be trusted</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>post_17</td>\n",
       "      <td>Are not biased</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>post_18</td>\n",
       "      <td>Want me to find an option that best fits my needs</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>post_19</td>\n",
       "      <td>Are a good way to get suggestions from a neutr...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>post_20</td>\n",
       "      <td>I would use the system to get book recommendat...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>post_21</td>\n",
       "      <td>I would use the system to find a new book to r...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>post_22</td>\n",
       "      <td>I would use the system to make finding a book ...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>post_23</td>\n",
       "      <td>I would use the system to relax my mind.</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>post_24</td>\n",
       "      <td>I would use the system to have an enjoyable time.</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>post_25</td>\n",
       "      <td>I would use the system for fun.</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>post_26</td>\n",
       "      <td>When I use the system, I have enjoyment.</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>post_27</td>\n",
       "      <td>I enjoyed doing this activity very much</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>post_28</td>\n",
       "      <td>This activity was fun to do</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>post_29</td>\n",
       "      <td>I thought this was a boring activity</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>post_30</td>\n",
       "      <td>This activity did not hold my attention at all</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>post_31</td>\n",
       "      <td>I thought this activity was quite enjoyable</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>post_32</td>\n",
       "      <td>Fake-Natural</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>post_33</td>\n",
       "      <td>Machinelike-Humanlike</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>post_34</td>\n",
       "      <td>Unconsious-Conscious</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>post_35</td>\n",
       "      <td>Artificial-Lifelike</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>post_36</td>\n",
       "      <td>Reading is one of my main hobbies.</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>post_37</td>\n",
       "      <td>I rely on recommender systems to help me make ...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>post_38</td>\n",
       "      <td>I am someone who does a thorough job</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>post_39</td>\n",
       "      <td>I am someone who can be somewhat careless</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>post_40</td>\n",
       "      <td>I am someone who tends to be disorganized</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>post_41</td>\n",
       "      <td>I am someone who perseveres until the task is ...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>post_42</td>\n",
       "      <td>I am someone who does things efficiently</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           question  scale\n",
       "0     pre_2  Overall, I am satisfied with how easy it is to...      7\n",
       "1     pre_3                   It is simple to use this system.      7\n",
       "2     pre_4              I feel comfortable using this system.      7\n",
       "3     pre_5  The information (such as online help, on-scree...      7\n",
       "4     pre_6          It is easy to find the infromation I need      7\n",
       "5     pre_7  The information provded with the system is eas...      7\n",
       "6    post_8                         Provide useful suggestions      7\n",
       "7    post_9                              Make decisions easier      7\n",
       "8   post_10  Are a good way to learn about different produc...      7\n",
       "9   post_11  Offer suggestions that I might not have though...      7\n",
       "10  post_12  Have access to and can process more informatio...      7\n",
       "11  post_13                                       Are reliable      7\n",
       "12  post_14                                     Are dependable      7\n",
       "13  post_15      Are designed with the best intentions in mind      7\n",
       "14  post_16                                     Can be trusted      7\n",
       "15  post_17                                     Are not biased      7\n",
       "16  post_18  Want me to find an option that best fits my needs      7\n",
       "17  post_19  Are a good way to get suggestions from a neutr...      7\n",
       "18  post_20  I would use the system to get book recommendat...      7\n",
       "19  post_21  I would use the system to find a new book to r...      7\n",
       "20  post_22  I would use the system to make finding a book ...      7\n",
       "21  post_23           I would use the system to relax my mind.      7\n",
       "22  post_24  I would use the system to have an enjoyable time.      7\n",
       "23  post_25                    I would use the system for fun.      7\n",
       "24  post_26           When I use the system, I have enjoyment.      7\n",
       "25  post_27            I enjoyed doing this activity very much      7\n",
       "26  post_28                        This activity was fun to do      7\n",
       "27  post_29               I thought this was a boring activity      7\n",
       "28  post_30     This activity did not hold my attention at all      7\n",
       "29  post_31        I thought this activity was quite enjoyable      7\n",
       "30  post_32                                       Fake-Natural      7\n",
       "31  post_33                              Machinelike-Humanlike      7\n",
       "32  post_34                               Unconsious-Conscious      7\n",
       "33  post_35                                Artificial-Lifelike      7\n",
       "34  post_36                 Reading is one of my main hobbies.      7\n",
       "35  post_37  I rely on recommender systems to help me make ...      7\n",
       "36  post_38               I am someone who does a thorough job      7\n",
       "37  post_39          I am someone who can be somewhat careless      7\n",
       "38  post_40          I am someone who tends to be disorganized      7\n",
       "39  post_41  I am someone who perseveres until the task is ...      7\n",
       "40  post_42           I am someone who does things efficiently      7"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_and_concat_propositions(engine, group_prefix):\n",
    "    tables = inspector.get_table_names()  # Retrieve all table names from the database\n",
    "    # Filter tables to only include those containing \"pre_propositions\" or \"propositions\" and match the group prefix\n",
    "    proposition_names = [table.replace(group_prefix, '') for table in tables if (\"pre_propositions\" in table or \"propositions\" in table) and table.startswith(group_prefix)]\n",
    "    \n",
    "    dfs = []  # List to store individual DataFrames\n",
    "    for proposition_name in proposition_names:\n",
    "        # Determine prefix based on proposition_name pattern\n",
    "        if \"pre_propositions\" in proposition_name:\n",
    "            prefix = 'pre_'\n",
    "        elif proposition_name.startswith('propositions'):\n",
    "            prefix = 'post_'\n",
    "        else:\n",
    "            prefix = ''  # Default prefix if none of the conditions match\n",
    "\n",
    "        table_name = f\"{group_prefix}{proposition_name}\" if group_prefix else proposition_name\n",
    "        query = f\"SELECT * FROM {table_name}\"\n",
    "        df = pd.read_sql(query, engine)\n",
    "        string_columns = ['id']\n",
    "        for col in string_columns:\n",
    "            df[col] = df[col].apply(lambda x: f\"{prefix}{x}\")\n",
    "        dfs.append(df)\n",
    "    \n",
    "    # Concatenate all DataFrames in the list\n",
    "    if dfs:\n",
    "        concatenated_df = pd.concat(dfs, ignore_index=True)\n",
    "        return concatenated_df\n",
    "    else:\n",
    "        print(\"No tables found or loaded.\")\n",
    "\n",
    "# Example usage\n",
    "group_prefix = \"group21_\"  # !!!! Define the group prefix here !!!\n",
    "\n",
    "df_item_id = load_and_concat_propositions(engine, group_prefix)\n",
    "df_item_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_item_id.to_csv(f'{group_prefix}item ids.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next code cell we are selecting all the columns starting with \"user\"\n",
    "except for the \"users\" column (as it does not include any relevant information\n",
    "for us). Now we have a list of all the columns that we later want to retrieve\n",
    "data for. By taking this approach, our code works for all kinds of different\n",
    "columns starting with \"user\" since they are different from group to group.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select all the user columns\n",
    "usercols = [n for n in tables if 'user' in n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['group21_userallergies',\n",
       " 'group21_userconsent',\n",
       " 'group21_userdemograph',\n",
       " 'group21_usermancheck',\n",
       " 'group21_userpresatisfaction',\n",
       " 'group21_users',\n",
       " 'group21_usersatisfaction',\n",
       " 'group21_usersatisfaction1',\n",
       " 'group21_usersatisfaction2',\n",
       " 'group21_usersatisfaction3',\n",
       " 'group21_usersatisfaction4',\n",
       " 'group21_userselection']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usercols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell we are defining a function that makes it possible for us later\n",
    "to also add a prefix to column names which we will use later.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to add prefix to all columns except 'userId'\n",
    "def add_prefix_except_userid(df, prefix):\n",
    "    return df.rename(columns={col: f\"{prefix}{col}\" if col != \"userId\" else col for col in df.columns})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell we are now finally retrieving our data: We take the names\n",
    "of all the columns we identified as relevant (usercols), retrieve their content,\n",
    "and put them all in a list. There are two types of tables that first need some\n",
    "more work: userpresatisfaction(1) and usersatisfaction(1). These are the likert\n",
    "scale items and they are stored in so-called long format (meaning that every\n",
    "person appears in as many rows as are items in the likert scale, so if there is\n",
    "a likert scale with 14 items there are 14 rows per study participant). As the\n",
    "long format is not very useful for us to further work with the data, we convert\n",
    "it into wide format (you can see the command below, .pivot) so that all the\n",
    "tables are in the same format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for col in usercols:\n",
    "    query = f\"SELECT * FROM {col}\"\n",
    "    tablecontent = pd.read_sql(query, engine)\n",
    "    if 'userpresatisfaction' in col:\n",
    "        tablecontent = tablecontent.pivot(index='userId', columns='questionId', values='value').reset_index()\n",
    "        tablecontent.columns.name = None\n",
    "        tablecontent = add_prefix_except_userid(tablecontent, 'pre_')\n",
    "    elif 'usersatisfaction' in col:\n",
    "        tablecontent = tablecontent.pivot(index='userId', columns='questionId', values='value').reset_index()\n",
    "        tablecontent.columns.name = None\n",
    "        tablecontent = add_prefix_except_userid(tablecontent, 'post_')\n",
    "    elif 'userdemograph' in col: # !!! add more elif conditions and adapt table names if there are multiple extra 'time' columns !!!\n",
    "        # drop column 'time'\n",
    "        try:\n",
    "            tablecontent = tablecontent.drop(columns=['time'])\n",
    "        except:\n",
    "            pass\n",
    "    elif col == group_prefix + 'users':\n",
    "        tablecontent = tablecontent.rename(columns={'time': 'start_time'})\n",
    "    dfs.append(tablecontent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[     userId  genre\n",
       " 0         5      2\n",
       " 1         5      2\n",
       " 2       534      2\n",
       " 3       535      2\n",
       " 4       536      1\n",
       " ..      ...    ...\n",
       " 218     720      4\n",
       " 219     721      4\n",
       " 220     722      2\n",
       " 221     723      1\n",
       " 222     724      4\n",
       " \n",
       " [223 rows x 2 columns],\n",
       "     userId  consent\n",
       " 0      532        1\n",
       " 1      556        1\n",
       " 2      558        1\n",
       " 3      559        1\n",
       " 4      583        1\n",
       " ..     ...      ...\n",
       " 82     716        1\n",
       " 83     715        1\n",
       " 84     721        1\n",
       " 85     722        1\n",
       " 86     723        1\n",
       " \n",
       " [87 rows x 2 columns],\n",
       "     userId  age  gender  device  education\n",
       " 0      587   23       2       2          1\n",
       " 1      588   23       2       2          2\n",
       " 2      589   23       1       2          2\n",
       " 3      590   20       1       2          2\n",
       " 4      594   19       1       2          2\n",
       " ..     ...  ...     ...     ...        ...\n",
       " 76     716   59       1       2          2\n",
       " 77     715   54       2       2          4\n",
       " 78     721   19       2       2          2\n",
       " 79     722   22       2       2          4\n",
       " 80     723   21       1       2          2\n",
       " \n",
       " [81 rows x 5 columns],\n",
       "      userId  mancheck1  mancheck2\n",
       " 0         4          6          1\n",
       " 1         4          6          1\n",
       " 2       548          0          2\n",
       " 3       549          0          1\n",
       " 4       550          0          5\n",
       " ..      ...        ...        ...\n",
       " 109     715          0          1\n",
       " 110     721          0          5\n",
       " 111     722          0          2\n",
       " 112     723          1          6\n",
       " 113     724          1          4\n",
       " \n",
       " [114 rows x 3 columns],\n",
       "      userId  pre_1  pre_2  pre_3  pre_4  pre_5  pre_6  pre_7  pre_11  pre_12  \\\n",
       " 0       485    4.0    2.0    2.0    2.0    2.0    NaN    NaN     2.0     2.0   \n",
       " 1       488    4.0    2.0    2.0    2.0    2.0    NaN    NaN     2.0     2.0   \n",
       " 2       489    3.0    2.0    2.0    2.0    2.0    NaN    NaN     2.0     2.0   \n",
       " 3       492    3.0    2.0    2.0    2.0    2.0    NaN    NaN     2.0     2.0   \n",
       " 4       497    3.0    3.0    2.0    2.0    2.0    NaN    NaN     2.0     2.0   \n",
       " ..      ...    ...    ...    ...    ...    ...    ...    ...     ...     ...   \n",
       " 131     716    NaN    1.0    1.0    1.0    1.0    1.0    1.0     NaN     NaN   \n",
       " 132     721    NaN    4.0    7.0    5.0    5.0    5.0    5.0     NaN     NaN   \n",
       " 133     722    NaN    6.0    5.0    5.0    4.0    4.0    6.0     NaN     NaN   \n",
       " 134     723    NaN    7.0    7.0    7.0    6.0    6.0    6.0     NaN     NaN   \n",
       " 135     724    NaN    7.0    7.0    7.0    4.0    4.0    7.0     NaN     NaN   \n",
       " \n",
       "      ...  pre_16  pre_21  pre_22  pre_23  pre_24  pre_25  pre_26  pre_31  \\\n",
       " 0    ...     2.0     2.0     2.0     2.0     2.0     2.0     2.0     2.0   \n",
       " 1    ...     2.0     2.0     2.0     2.0     2.0     2.0     2.0     2.0   \n",
       " 2    ...     2.0     2.0     2.0     2.0     2.0     2.0     2.0     2.0   \n",
       " 3    ...     2.0     2.0     2.0     2.0     2.0     2.0     2.0     2.0   \n",
       " 4    ...     2.0     2.0     2.0     2.0     2.0     2.0     2.0     2.0   \n",
       " ..   ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       " 131  ...     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       " 132  ...     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       " 133  ...     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       " 134  ...     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       " 135  ...     NaN     NaN     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       " \n",
       "      pre_32  pre_33  \n",
       " 0       2.0     2.0  \n",
       " 1       2.0     2.0  \n",
       " 2       2.0     2.0  \n",
       " 3       2.0     2.0  \n",
       " 4       2.0     2.0  \n",
       " ..      ...     ...  \n",
       " 131     NaN     NaN  \n",
       " 132     NaN     NaN  \n",
       " 133     NaN     NaN  \n",
       " 134     NaN     NaN  \n",
       " 135     NaN     NaN  \n",
       " \n",
       " [136 rows x 23 columns],\n",
       "      userId  conditie                                           prolific  \\\n",
       " 0         1         3                       https://recipe-study.wur.nl/   \n",
       " 1         2         3                       https://recipe-study.wur.nl/   \n",
       " 2         3         2                       https://recipe-study.wur.nl/   \n",
       " 3         4         3                              74712973713jnfakjdnad   \n",
       " 4         5         1                              74712973713jnfakjdnad   \n",
       " ..      ...       ...                                                ...   \n",
       " 719     720         1  https://recipe-study.wur.nl/group21_bookrecomm...   \n",
       " 720     721         1  https://recipe-study.wur.nl/group21_bookrecomm...   \n",
       " 721     722         0  https://recipe-study.wur.nl/group21_bookrecomm...   \n",
       " 722     723         0  https://recipe-study.wur.nl/group21_bookrecomm...   \n",
       " 723     724         1  https://recipe-study.wur.nl/group21_bookrecomm...   \n",
       " \n",
       "              start_time  \n",
       " 0   2024-06-14 16:30:43  \n",
       " 1   2024-06-14 16:30:43  \n",
       " 2   2024-06-14 16:30:43  \n",
       " 3   2024-06-14 16:30:43  \n",
       " 4   2024-06-14 16:30:43  \n",
       " ..                  ...  \n",
       " 719 2024-06-23 01:36:53  \n",
       " 720 2024-06-23 01:38:36  \n",
       " 721 2024-06-23 15:17:58  \n",
       " 722 2024-06-23 16:17:09  \n",
       " 723 2024-06-23 23:47:10  \n",
       " \n",
       " [724 rows x 4 columns],\n",
       "      userId  post_1  post_2  post_3  post_4  post_5  post_8  post_9  post_10  \\\n",
       " 0       510     4.0     2.0     2.0     2.0     2.0     NaN     NaN      NaN   \n",
       " 1       516     NaN     NaN     3.0     3.0     3.0     NaN     NaN      NaN   \n",
       " 2       517     NaN     NaN     2.0     2.0     2.0     NaN     NaN      NaN   \n",
       " 3       518     NaN     NaN     2.0     2.0     2.0     NaN     NaN      NaN   \n",
       " 4       519     NaN     NaN     3.0     3.0     3.0     NaN     NaN      NaN   \n",
       " ..      ...     ...     ...     ...     ...     ...     ...     ...      ...   \n",
       " 105     715     NaN     NaN     NaN     NaN     NaN     5.0     5.0      5.0   \n",
       " 106     716     NaN     NaN     NaN     NaN     NaN     1.0     1.0      1.0   \n",
       " 107     721     NaN     NaN     NaN     NaN     NaN     5.0     5.0      3.0   \n",
       " 108     722     NaN     NaN     NaN     NaN     NaN     6.0     6.0      6.0   \n",
       " 109     723     NaN     NaN     NaN     NaN     NaN     5.0     5.0      4.0   \n",
       " \n",
       "      post_11  ...  post_33  post_34  post_35  post_36  post_37  post_38  \\\n",
       " 0        2.0  ...      2.0      NaN      NaN      NaN      NaN      NaN   \n",
       " 1        3.0  ...      2.0      NaN      NaN      NaN      NaN      NaN   \n",
       " 2        2.0  ...      2.0      NaN      NaN      NaN      NaN      NaN   \n",
       " 3        2.0  ...      2.0      NaN      NaN      NaN      NaN      NaN   \n",
       " 4        2.0  ...      2.0      NaN      NaN      NaN      NaN      NaN   \n",
       " ..       ...  ...      ...      ...      ...      ...      ...      ...   \n",
       " 105      5.0  ...      NaN      NaN      NaN      NaN      NaN      NaN   \n",
       " 106      1.0  ...      NaN      NaN      NaN      NaN      NaN      NaN   \n",
       " 107      4.0  ...      NaN      NaN      NaN      NaN      NaN      NaN   \n",
       " 108      6.0  ...      NaN      NaN      NaN      NaN      NaN      NaN   \n",
       " 109      4.0  ...      NaN      NaN      NaN      NaN      NaN      NaN   \n",
       " \n",
       "      post_39  post_40  post_41  post_42  \n",
       " 0        NaN      NaN      NaN      NaN  \n",
       " 1        NaN      NaN      NaN      NaN  \n",
       " 2        NaN      NaN      NaN      NaN  \n",
       " 3        NaN      NaN      NaN      NaN  \n",
       " 4        NaN      NaN      NaN      NaN  \n",
       " ..       ...      ...      ...      ...  \n",
       " 105      NaN      NaN      NaN      NaN  \n",
       " 106      NaN      NaN      NaN      NaN  \n",
       " 107      NaN      NaN      NaN      NaN  \n",
       " 108      NaN      NaN      NaN      NaN  \n",
       " 109      NaN      NaN      NaN      NaN  \n",
       " \n",
       " [110 rows x 41 columns],\n",
       "     userId  post_20  post_21  post_22  post_23  post_24  post_25  post_26  \\\n",
       " 0      557        3        2        2        2        2        2        2   \n",
       " 1      558        3        3        3        3        3        2        2   \n",
       " 2      559        3        2        2        2        2        2        2   \n",
       " 3      583        3        2        2        2        2        2        2   \n",
       " 4      586        4        2        2        2        2        2        2   \n",
       " ..     ...      ...      ...      ...      ...      ...      ...      ...   \n",
       " 80     715        5        5        5        2        6        5        3   \n",
       " 81     716        1        1        1        1        1        6        6   \n",
       " 82     721        4        5        5        3        3        4        4   \n",
       " 83     722        5        6        6        5        6        5        6   \n",
       " 84     723        5        5        5        7        7        7        4   \n",
       " \n",
       "     post_27  post_28  post_29  post_30  post_31  \n",
       " 0         2        2        2        2        2  \n",
       " 1         2        2        2        2        2  \n",
       " 2         2        2        2        2        2  \n",
       " 3         2        2        2        3        2  \n",
       " 4         2        2        2        2        2  \n",
       " ..      ...      ...      ...      ...      ...  \n",
       " 80        7        3        6        2        7  \n",
       " 81        6        6        6        6        6  \n",
       " 82        4        4        1        1        4  \n",
       " 83        4        4        3        3        6  \n",
       " 84        4        4        7        6        7  \n",
       " \n",
       " [85 rows x 13 columns],\n",
       "     userId  post_32  post_33  post_34  post_35\n",
       " 0      558        4        4        4        4\n",
       " 1      559        4        4        4        4\n",
       " 2      583        4        2        2        2\n",
       " 3      586        4        2        2        2\n",
       " 4      587        2        2        3        3\n",
       " ..     ...      ...      ...      ...      ...\n",
       " 80     715        4        4        4        4\n",
       " 81     716        1        1        1        1\n",
       " 82     721        4        3        4        4\n",
       " 83     722        2        2        2        2\n",
       " 84     723        4        7        7        7\n",
       " \n",
       " [85 rows x 5 columns],\n",
       "     userId  post_36  post_37\n",
       " 0      558        3        3\n",
       " 1      559        4        4\n",
       " 2      583        4        4\n",
       " 3      586        4        4\n",
       " 4      587        3        3\n",
       " ..     ...      ...      ...\n",
       " 81     715        6        6\n",
       " 82     716        6        1\n",
       " 83     721        5        4\n",
       " 84     722        5        5\n",
       " 85     723        2        6\n",
       " \n",
       " [86 rows x 3 columns],\n",
       "     userId  post_38  post_39  post_40  post_41  post_42\n",
       " 0      558        4        4        4        4        4\n",
       " 1      559        4        4        4        4        4\n",
       " 2      583        4        2        2        2        2\n",
       " 3      586        4        2        2        2        2\n",
       " 4      587        3        2        2        2        2\n",
       " ..     ...      ...      ...      ...      ...      ...\n",
       " 81     715        4        2        1        5        4\n",
       " 82     716        6        1        1        6        6\n",
       " 83     721        5        3        4        3        4\n",
       " 84     722        6        5        3        6        4\n",
       " 85     723        6        6        4        7        4\n",
       " \n",
       " [86 rows x 6 columns],\n",
       "      userId  conditie  calibrationId  recommendationId\n",
       " 0       507         0            626               174\n",
       " 1       508         1            626               683\n",
       " 2       510         0             13              2017\n",
       " 3       511         0              5              2152\n",
       " 4       512         1            626              1140\n",
       " ..      ...       ...            ...               ...\n",
       " 138     715         1           1277              1278\n",
       " 139     721         1           1914               414\n",
       " 140     722         0            929              2262\n",
       " 141     723         0            151               132\n",
       " 142     724         1           1295              1715\n",
       " \n",
       " [143 rows x 4 columns]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we merge all the tables we collected in the list together on userId so that\n",
    "we have one row per user with all the variables in one column each. We also\n",
    "further remove some variables that are not of interest to us (such as time\n",
    "variables) to further clean the dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge all DataFrames on the userId column\n",
    "merged_df = dfs[0]\n",
    "for df in dfs[1:]:\n",
    "    merged_df = pd.merge(merged_df, df, on='userId', how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if there are duplicated 'userId' in merged_df and drop duplicates\n",
    "merged_df.drop_duplicates(subset='userId', keep='last', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the start_time column to datetime format\n",
    "merged_df['start_time'] = pd.to_datetime(merged_df['start_time'])\n",
    "\n",
    "# remove start_time before 20 June 2024\n",
    "merged_df = merged_df[merged_df['start_time'] >= '2024-06-20']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>genre</th>\n",
       "      <th>consent</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>device</th>\n",
       "      <th>education</th>\n",
       "      <th>mancheck1</th>\n",
       "      <th>mancheck2</th>\n",
       "      <th>pre_1</th>\n",
       "      <th>...</th>\n",
       "      <th>post_36_y</th>\n",
       "      <th>post_37_y</th>\n",
       "      <th>post_38_y</th>\n",
       "      <th>post_39_y</th>\n",
       "      <th>post_40_y</th>\n",
       "      <th>post_41_y</th>\n",
       "      <th>post_42_y</th>\n",
       "      <th>conditie_y</th>\n",
       "      <th>calibrationId</th>\n",
       "      <th>recommendationId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>560</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>561</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>562</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>563</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>564</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>720</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>721</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1914.0</td>\n",
       "      <td>414.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>722</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>929.0</td>\n",
       "      <td>2262.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>768</th>\n",
       "      <td>723</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>132.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769</th>\n",
       "      <td>724</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1295.0</td>\n",
       "      <td>1715.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>165 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     userId  genre  consent   age  gender  device  education  mancheck1  \\\n",
       "579     560    2.0      NaN   NaN     NaN     NaN        NaN        NaN   \n",
       "580     561    2.0      NaN   NaN     NaN     NaN        NaN        NaN   \n",
       "581     562    3.0      NaN   NaN     NaN     NaN        NaN        NaN   \n",
       "582     563    3.0      NaN   NaN     NaN     NaN        NaN        NaN   \n",
       "583     564    3.0      NaN   NaN     NaN     NaN        NaN        NaN   \n",
       "..      ...    ...      ...   ...     ...     ...        ...        ...   \n",
       "765     720    4.0      NaN   NaN     NaN     NaN        NaN        NaN   \n",
       "766     721    4.0      1.0  19.0     2.0     2.0        2.0        0.0   \n",
       "767     722    2.0      1.0  22.0     2.0     2.0        4.0        0.0   \n",
       "768     723    1.0      1.0  21.0     1.0     2.0        2.0        1.0   \n",
       "769     724    4.0      NaN   NaN     NaN     NaN        NaN        1.0   \n",
       "\n",
       "     mancheck2  pre_1  ...  post_36_y  post_37_y  post_38_y  post_39_y  \\\n",
       "579        NaN    NaN  ...        NaN        NaN        NaN        NaN   \n",
       "580        NaN    NaN  ...        NaN        NaN        NaN        NaN   \n",
       "581        NaN    NaN  ...        NaN        NaN        NaN        NaN   \n",
       "582        NaN    NaN  ...        NaN        NaN        NaN        NaN   \n",
       "583        NaN    NaN  ...        NaN        NaN        NaN        NaN   \n",
       "..         ...    ...  ...        ...        ...        ...        ...   \n",
       "765        NaN    NaN  ...        NaN        NaN        NaN        NaN   \n",
       "766        5.0    NaN  ...        5.0        4.0        5.0        3.0   \n",
       "767        2.0    NaN  ...        5.0        5.0        6.0        5.0   \n",
       "768        6.0    NaN  ...        2.0        6.0        6.0        6.0   \n",
       "769        4.0    NaN  ...        NaN        NaN        NaN        NaN   \n",
       "\n",
       "     post_40_y  post_41_y  post_42_y  conditie_y  calibrationId  \\\n",
       "579        NaN        NaN        NaN         NaN            NaN   \n",
       "580        NaN        NaN        NaN         NaN            NaN   \n",
       "581        NaN        NaN        NaN         NaN            NaN   \n",
       "582        NaN        NaN        NaN         NaN            NaN   \n",
       "583        NaN        NaN        NaN         NaN            NaN   \n",
       "..         ...        ...        ...         ...            ...   \n",
       "765        NaN        NaN        NaN         NaN            NaN   \n",
       "766        4.0        3.0        4.0         1.0         1914.0   \n",
       "767        3.0        6.0        4.0         0.0          929.0   \n",
       "768        4.0        7.0        4.0         0.0          151.0   \n",
       "769        NaN        NaN        NaN         1.0         1295.0   \n",
       "\n",
       "     recommendationId  \n",
       "579               NaN  \n",
       "580               NaN  \n",
       "581               NaN  \n",
       "582               NaN  \n",
       "583               NaN  \n",
       "..                ...  \n",
       "765               NaN  \n",
       "766             414.0  \n",
       "767            2262.0  \n",
       "768             132.0  \n",
       "769            1715.0  \n",
       "\n",
       "[165 rows x 100 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a last step, we save the dataframe to a CSV file. We have now called this\n",
    "dataframe final_df.csv, you can change the name if you want -- just make sure\n",
    "you can find the dataframe after you have saved it. With this code, it is stored\n",
    "in the same folder as your Python script.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv(f'{group_prefix}final_df.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
